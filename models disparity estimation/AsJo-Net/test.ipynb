{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import grad as Grad\n",
    "from torchvision import transforms\n",
    "import skimage.io\n",
    "import os\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm, trange\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import __models__\n",
    "from datasets import __datasets__\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from utils import *\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Accurate and Real-Time Stereo Matching via Context and Geometry Interaction (CGI-Stereo)')\n",
    "parser.add_argument('--model', default='CGI_Stereo', help='select a model structure', choices=__models__.keys())\n",
    "parser.add_argument('--maxdisp', type=int, default=192, help='maximum disparity')\n",
    "parser.add_argument('--datapath', default=\"/data/KITTI/KITTI_2015/training/\", help='data path')\n",
    "parser.add_argument('--kitti', type=str, default='2015')\n",
    "parser.add_argument('--loadckpt', default='./pretrained_models/CGI_Stereo/sceneflow.ckpt',help='load the weights from a specific checkpoint')\n",
    "\n",
    "args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "@dataclass\n",
    "class Args:\n",
    "    model: str           = 'CGI_Stereo'\n",
    "    # maxdisp: int         = 192\n",
    "    dataset: str         = 'scape_pipes'\n",
    "    # datapath: str        = r\"C:\\Users\\\"\n",
    "    # trainlist: str       = \"full_aug_combined_rectified_scape_dataset_train.txt\"\n",
    "    testlist: str        = \"full_aug_combined_rectified_scape_dataset_test.txt\"\n",
    "    # lr: float            = 0.001\n",
    "    # batch_size: int      = 8\n",
    "    # test_batch_size: int = 2\n",
    "    # epochs: int          = 100\n",
    "    # lrepochs: str        = \"10,14,16,18:2\"\n",
    "    # logdir: str          = r\"C:\\Users\\\"\n",
    "    # # loadckpt: str        = r\"C:\\Users\\\"\n",
    "    # loadckpt: str        = r\"\"\n",
    "    # resume: bool         = False\n",
    "    # seed: int            = 1\n",
    "    # summary_freq: int    = 5\n",
    "    # save_freq: int       = 1\n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scan_folder        = os.path.join(BASE_PATH, 'data_3/ainstec')\n",
    "image_folder_left  = os.path.join(BASE_PATH, 'data_3/multicast_rect_reso/camera1')\n",
    "image_folder_right = os.path.join(BASE_PATH, 'data_3/multicast_rect_reso/camera2')\n",
    "output_path        = os.path.join(BASE_PATH, 'data_3/ground_truth_pfm_rect')\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "list_of_scans_folders: List[str] = sorted(os.listdir(scan_folder))\n",
    "list_of_left_images:   List[str] = sorted([os.path.join(image_folder_left , x) for x in os.listdir(image_folder_left ) if x != '.DS_Store'])\n",
    "list_of_right_images:  List[str] = sorted([os.path.join(image_folder_right, x) for x in os.listdir(image_folder_right) if x != '.DS_Store'])\n",
    "\n",
    "list_of_scans_paths: List[str] = []\n",
    "for subfolder in list_of_scans_folders:\n",
    "    if str(subfolder) == \".DS_Store\":\n",
    "        continue\n",
    "    folder_path = os.path.join(scan_folder, subfolder)\n",
    "    pcd_files = [os.path.join(folder_path, x) for x in os.listdir(folder_path) if x.endswith('.pcd')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StereoDataset = __datasets__[args.dataset]\n",
    "test_dataset = StereoDataset(args.datapath, args.testlist, False)\n",
    "TestImgLoader = DataLoader(test_dataset, args.test_batch_size, shuffle=False, num_workers=2, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.kitti == '2015':\n",
    "    all_limg, all_rimg, all_ldisp, test_limg, test_rimg, test_ldisp = kt2015.kt2015_loader(args.datapath)\n",
    "else:\n",
    "    all_limg, all_rimg, all_ldisp, test_limg, test_rimg, test_ldisp = kt2012.kt2012_loader(args.datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, sample in enumerate(TestImgLoader):\n",
    "    print(len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, sample in enumerate(TestImgLoader):\n",
    "    model = __models__[args.model](args.maxdisp)\n",
    "    model = nn.DataParallel(model)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    if args.loadckpt is not None:\n",
    "        state_dict = torch.load(args.loadckpt)\n",
    "        model.load_state_dict(state_dict['state_dict'], strict=False)\n",
    "\n",
    "    imgL = sample['left'].cuda()\n",
    "    imgR = sample['right'].cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        disp = model(imgL, imgR)\n",
    "\n",
    "    disp = torch.squeeze(disp)\n",
    "    disp = disp.data.cpu().numpy()\n",
    "\n",
    "    for i in range(disp.shape[0]):\n",
    "        disp_map = disp[i]\n",
    "        disp_map = (disp_map * 256).astype(np.uint16)\n",
    "\n",
    "        img_name = test_limg[batch_idx * args.test_batch_size + i].split('/')[-1]\n",
    "        skimage.io.imsave(os.path.join(output_path, img_name[:-4] + '.png'), disp_map)\n",
    "\n",
    "    if batch_idx % 10 == 0:\n",
    "        print('Iter %d' % batch_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_limg = all_limg + test_limg\n",
    "test_rimg = all_rimg + test_rimg\n",
    "test_ldisp = all_ldisp + test_ldisp\n",
    "\n",
    "model = __models__[args.model](args.maxdisp)\n",
    "model = nn.DataParallel(model)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "state_dict = torch.load(args.loadckpt)\n",
    "model.load_state_dict(state_dict['model'])\n",
    "\n",
    "pred_mae = 0\n",
    "pred_op = 0\n",
    "for i in trange(len(test_limg)):\n",
    "    limg = Image.open(test_limg[i]).convert('RGB')\n",
    "    rimg = Image.open(test_rimg[i]).convert('RGB')\n",
    "\n",
    "    w, h = limg.size\n",
    "    m = 32\n",
    "    wi, hi = (w // m + 1) * m, (h // m + 1) * m\n",
    "    limg = limg.crop((w - wi, h - hi, w, h))\n",
    "    rimg = rimg.crop((w - wi, h - hi, w, h))\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    limg_tensor = transform(limg)\n",
    "    rimg_tensor = transform(rimg)\n",
    "    limg_tensor = limg_tensor.unsqueeze(0).cuda()\n",
    "    rimg_tensor = rimg_tensor.unsqueeze(0).cuda()\n",
    "\n",
    "    disp_gt = Image.open(test_ldisp[i])\n",
    "    disp_gt = np.ascontiguousarray(disp_gt, dtype=np.float32) / 256\n",
    "    gt_tensor = torch.FloatTensor(disp_gt).unsqueeze(0).unsqueeze(0).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_disp  = model(limg_tensor, rimg_tensor)[-1]\n",
    "        pred_disp = pred_disp[:, hi - h:, wi - w:]\n",
    "\n",
    "    predict_np = pred_disp.squeeze().cpu().numpy()\n",
    "\n",
    "    op_thresh = 3\n",
    "    mask = (disp_gt > 0) & (disp_gt < args.maxdisp)\n",
    "    error = np.abs(predict_np * mask.astype(np.float32) - disp_gt * mask.astype(np.float32))\n",
    "\n",
    "    pred_error = np.abs(predict_np * mask.astype(np.float32) - disp_gt * mask.astype(np.float32))\n",
    "    pred_op += np.sum((pred_error > op_thresh)) / np.sum(mask)\n",
    "    pred_mae += np.mean(pred_error[mask])\n",
    "\n",
    "    # print(\"#### >3.0\", np.sum((pred_error > op_thresh)) / np.sum(mask))\n",
    "    # print(\"#### EPE\", np.mean(pred_error[mask]))\n",
    "\n",
    "print(\"#### EPE\", pred_mae / len(test_limg))\n",
    "print(\"#### >3.0\", pred_op / len(test_limg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speciale",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
